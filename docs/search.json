[
  {
    "objectID": "posts/Implementing-Statistics/Implementing-Statistics.html",
    "href": "posts/Implementing-Statistics/Implementing-Statistics.html",
    "title": "Logistic Regression",
    "section": "",
    "text": "The simple answer is the logistic regression is a way to classify a binary target. So if you have a bunch of features in order to tell you if you’re looking at a dog or a cat, you could in theory train a logistic regression algorithm on said features to tell you the next time you see an animal if the animal is a dog or a cat.\nThe slightly more in depth answer is that the logistic equation is defined like so:\n\\[\np(\\bar{X}) = \\dfrac{e^{\\beta_{0} + \\beta_{1}X_{1} + \\dots + \\beta_{p}X_{p}}}{1 + e^{\\beta_{0} + \\beta_{1}X_{1} + \\dots + \\beta_{p}X_{p}}}\n\\]\nWhere we have \\(p(\\bar{X})\\) being the “real” function that defines the relationship between the features encoded in \\(\\bar{X} = (X_{0}, X_{1}, \\dots , X_{p})\\), and the coefficients \\(\\beta_{0}, \\dots , \\beta_{p}\\) are the coefficients which are “learned” in the machine learning process.\nNow any good statistics teacher will tell you that his isn’t the extent of what you should learn about logistic regression. However, I’m no statistics teacher (nor do I currently have time to go through this), so what I’ll say is that if you’re reading this post you should also take a look at the book Introduction to Statistical Learning which has a great discussion on this topic in Chapter 4. I’d also recommend this for anyone at all trying to learn statistics.\nGreat! Moving forward bravely to the next step, we’re going to look at how to use this for a very contrived and annoying problem, which we’re going to not only create ourselves, but we’ll also solve ourselves. Why? Because that’s the best way to learn, change my mind. So the basic idea is that we want to have certain features which will create a relatively binary output. We also want the target to rely on the features, in a binary fashion. That’s simple enough:"
  },
  {
    "objectID": "posts/Implementing-Statistics/Implementing-Statistics.html#data-generation",
    "href": "posts/Implementing-Statistics/Implementing-Statistics.html#data-generation",
    "title": "Logistic Regression",
    "section": "Data Generation",
    "text": "Data Generation\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n\ndef make_sample_data(minimum, maximum, resolution=1):\n    \"\"\"\n    Creates a grid of data points with a rough boundary line separating them in 2D.\n\n    Basic rule is:\n    x - y + noise >= -0.5\n\n    Args:\n        minimum      (int): Start point\n        maximum      (int): End point\n        resolution (float): How closely you want the points to be packed\n\n    Returns:\n        xx     (np.array): x coordinates\n        yy     (np.array): y coordinates\n        target (np.array): 1/0 output array based on rule\n    \"\"\"\n    x1 = np.arange(minimum, maximum, resolution)\n    x2 = np.arange(minimum, maximum, resolution)\n    xx, yy = np.meshgrid(x1, x2)\n    target = 10 * (\n        xx - yy + np.random.randint(low=-2, high=2, size=(len(xx), len(yy))) >= -0.5\n    )\n    return xx, yy, target\n\n\nx_sample, y_sample, target_sample = make_sample_data(1, 6, resolution=0.07)\n\nplt.figure(figsize=(8, 8))\nplt.title(\"Sample Data\")\nplt.scatter(x_sample, y_sample, c=target_sample)\nplt.xlim(left=min(x_sample[0]), right=max(x_sample[0]))\nplt.ylim(bottom=min(x_sample[0]), top=max(x_sample[0]))\nplt.xlabel(r\"$x_{0}$\")\nplt.ylabel(r\"$x_{1}$\")\nplt.show()\n\n\n\n\n\nTaking a look at the data we’ve created, we can say that there’s a (relatively) clear boundary present. The rule that I implemented is:\n\\[\nf(\\bar{X}) = \\begin{cases} 1,  & x_{0} - x_{1} + \\epsilon \\geq -0.5 \\\\ 0, & \\text{otherwise} \\end{cases}\n\\]\nWhere \\(\\bar{X} = (x_{0}, x_{1})\\)\nSo in the case of \\(\\bar{X} = (2, 4)\\) we have that the output will be -2, making the value of our function 1. That looks to chek out when we look at our figure above."
  },
  {
    "objectID": "posts/Implementing-Statistics/Implementing-Statistics.html#model-building",
    "href": "posts/Implementing-Statistics/Implementing-Statistics.html#model-building",
    "title": "Logistic Regression",
    "section": "Model Building",
    "text": "Model Building\nNow on to the part that most of you are here for: building a logistic model using sklearn\n\n\nCode\nfrom sklearn.linear_model import LogisticRegression\nimport pandas as pd\n\n\nOne last time, let’s take a look at our data, but in a different way this time. Lets look at it in 3D, so we can see the literal sigmoidal nature of our model:\n\n\nCode\nfig = plt.figure(figsize=(14, 7))\nax = plt.axes(projection=\"3d\")\nax.plot_surface(\n    x_sample, y_sample, target_sample, cmap=\"coolwarm\", rcount=200, ccount=200\n)\nax.set_xlabel(r\"$x_1$\")\nax.set_ylabel(r\"$x_2$\")\nax.zaxis.set_rotate_label(False)\nax.set_zlabel(r\"$f(x_{0},x_{1})$\", rotation=0)\nax.view_init(15, 70)\nplt.title(\"Training Data\")\nplt.show()\n\n\n\n\n\nNote the little section in the middle where we’ve added uncertainty. Everything else is relatively concrete in the output (we’re keeping it simple).\nNext step that we want to put our data in a nice dataframe and use LogisticRegression from sklearn.linear_model. This has some default that we’re going to use. Specifically, the “penalty” assigned to our training is the L2 norm. I’m going to make a post about the different types of penalty, but let’s keep it moving for now.\n\ndf = pd.DataFrame(\n    {\"x1\": x_sample.ravel(), \"x2\": y_sample.ravel(), \"target\": target_sample.ravel()}\n)\n\ndf.head()\n\n\n\n\n\n  \n    \n      \n      x1\n      x2\n      target\n    \n  \n  \n    \n      0\n      1.00\n      1.0\n      0\n    \n    \n      1\n      1.07\n      1.0\n      10\n    \n    \n      2\n      1.14\n      1.0\n      10\n    \n    \n      3\n      1.21\n      1.0\n      0\n    \n    \n      4\n      1.28\n      1.0\n      0\n    \n  \n\n\n\n\nThere’s our little table, and here’s how we can fit the logistic regression with the defaults:\n\nmodel = LogisticRegression(random_state=0)\nmodel.fit(df[[\"x1\", \"x2\"]], df.target)\n\nLogisticRegression(random_state=0)\n\n\nNow that we’ve fitted our data, we can do a few things. Yes, we can predict, but also importantly we can learn about the model itself. Remember the basic structure of the model? Well now we can determine what our model should have looked like. There are a few ways we can go about this, namely we can use the model.coef_ and model.intercept to manually calculate the output values, or we can just use model.predict. Now keep in mind I’m running the prediction on the training data, mainly so I can see if the structure was captured:\n\n\nCode\ndf[\"predictions\"] = model.predict(df[[\"x1\", \"x2\"]])\nfig = plt.figure(figsize=(14, 7))\nax = plt.axes(projection=\"3d\")\nax.plot_surface(\n    x_sample, y_sample, df[[\"predictions\"]].to_numpy().reshape(72, 72), cmap=\"coolwarm\"\n)\nax.set_xlabel(\"x1\")\nax.set_ylabel(\"x2\")\nax.set_zlabel(\"pred\")\nax.view_init(15, 70)\nplt.show()\n\n\n\n\n\nThat looks extremely similiar to the idea we had when we created the data. So on that note, I’m going to leave the basics of logistic regression here. Next up we can take a closer look at prediction and accuracy of the model."
  },
  {
    "objectID": "posts/2022-06-13-Linear-Regression-TF.html",
    "href": "posts/2022-06-13-Linear-Regression-TF.html",
    "title": "Linear Regression with minibatch gradient descent in TensorFlow",
    "section": "",
    "text": "Alright, so this is going to be a quick, not very in depth approach to linear regression with TensorFlow. A lot of the functions I’m using for this that have to do with TensorFlow will be explained in a later post where I describe everything as simply as possible with examples. Bear with me here. One note is that I’m taking section 3.2 of the d2l.ai book and trying to make it simpler, so you may see code overlap, but hopefully this will be much more informative and easier to read (after some revisions)."
  },
  {
    "objectID": "posts/2022-06-13-Linear-Regression-TF.html#data-generation",
    "href": "posts/2022-06-13-Linear-Regression-TF.html#data-generation",
    "title": "Linear Regression with minibatch gradient descent in TensorFlow",
    "section": "Data Generation",
    "text": "Data Generation\nThe simplest way to start as I always to is to generate the data. In this case, we’re looking to generate the data which has two features and one output. So our true equation will be of the form: \\[\ny = \\underline{X}\\bar{w} + \\bar{b}\n\\] Where \\(\\underline{X}\\) is a matrix, \\(\\bar{w}, \\bar{b}\\) are vectors. It’s important to know the dimensions of our matrix and vectors. Here we have \\(\\underline{X}\\) in the shape of (num_samples, num_features). So really that should be (\\(n\\), 2) where \\(n\\) is the number of samples we have. Our vectors on the other hand will be of the shape:\n\n\\(w\\): (num_samples, 1)\n\\(b\\): (num_samples, 1)\n\nTo be as clear as possible, our equation looks like this:\n\\[\n\\begin{bmatrix}\ny_1 \\\\\n\\vdots \\\\\ny_n\n\\end{bmatrix}\n=\n\\begin{bmatrix}\nx_{1,1} & x_{1,2} & \\dots & x_{1, p} \\\\\nx_{2,1} & x_{2,2} & \\dots & x_{2, p} \\\\\n\\vdots  & & \\ddots & \\vdots \\\\\nx_{n, 1} & x_{n, 2} & \\dots & x_{n, p}\n\\end{bmatrix}\n\\begin{bmatrix}\nw_1 \\\\\n\\vdots \\\\\nw_p\n\\end{bmatrix} +\n\\begin{bmatrix}\nb_1 \\\\\n\\vdots \\\\\nb_n\n\\end{bmatrix}\n\\]\nBy the way… this isn’t how you should usually look at linear regression. Usually you’d include \\(\\bar{b}\\) in \\(\\underline{X}\\) and \\(\\bar{w}\\), but to be more clear we’ll seperate it here.\nLast thing to keep in mind is that we’re adding noise (because otherwise it’s not very fun!). That noise vector \\(\\bar{\\epsilon}\\) will also have a shape of (\\(n\\), 1), making our final equation:\n\\[\n\\begin{bmatrix}\ny_1 \\\\\n\\vdots \\\\\ny_n\n\\end{bmatrix}\n=\n\\begin{bmatrix}\nx_{1,1} & x_{1,2} & \\dots & x_{1, p} \\\\\nx_{2,1} & x_{2,2} & \\dots & x_{2, p} \\\\\n\\vdots  & & \\ddots & \\vdots \\\\\nx_{n, 1} & x_{n, 2} & \\dots & x_{n, p}\n\\end{bmatrix}\n\\begin{bmatrix}\nw_1 \\\\\n\\vdots \\\\\nw_p\n\\end{bmatrix} +\n\\begin{bmatrix}\nb_1 \\\\\n\\vdots \\\\\nb_n\n\\end{bmatrix} +\n\\begin{bmatrix}\n\\epsilon_1 \\\\\n\\vdots \\\\\n\\epsilon_n\n\\end{bmatrix}\n\\]\n\ndef generate_data(w, b, num_samples):\n    \"\"\"\n    Create sample data of the form\n    \n    y = Xw + b + epsilon \n    \n    Where epsilon is random noise centered around 0, std dev 0.01\n    \"\"\"\n    X = tf.random.normal(shape=(num_samples, w.shape[0]))\n    w_reshaped = tf.reshape(w, shape=(-1, 1))\n    epsilon = tf.random.normal(shape=(num_samples, 1), stddev=0.01)\n    y = tf.matmul(X, w_reshaped) + b + epsilon\n    return X, y\n\n\ntrue_w = tf.constant([2, -3.4])\ntrue_b = 4.2\n\nfeatures, labels = generate_data(true_w, true_b, 1000)"
  },
  {
    "objectID": "posts/2022-06-13-Linear-Regression-TF.html#data-visualization",
    "href": "posts/2022-06-13-Linear-Regression-TF.html#data-visualization",
    "title": "Linear Regression with minibatch gradient descent in TensorFlow",
    "section": "Data Visualization",
    "text": "Data Visualization\nNow we used simple parameters of \\(w_1 = 2\\) and \\(w_2 = -3.4\\), with \\(b = 4.2\\). Here’s what our features look like:\n\n\nCode\nplt.figure(figsize=(14, 7))\nplt.title(r\"$Xw + b + \\epsilon$\")\nplt.scatter(features[:, 0], labels, label=\"Feature 1\")\nplt.scatter(features[:, 1], labels, label=\"Feature 2\")\nplt.xlabel(\"Feature Matrix\")\nplt.ylabel(\"Label\")\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\nCode\nfig = plt.figure(figsize = (14,14))\nax = plt.axes(projection='3d')\nax.scatter3D(features[:, 0], \n             features[:, 1], \n             labels, cmap = 'coolwarm')\nax.set_xlabel(r\"$x_1$\")\nax.set_ylabel(r\"$x_2$\")\nax.zaxis.set_rotate_label(False)\nax.set_zlabel(r\"$y$\", rotation = 0)\nax.view_init(20, 140)\nplt.title(\"Training Data\")\nplt.show()\n\n\n\n\n\nAs our second feature \\(X_{n, 2}\\) gets more negative and our first feature \\(X_{n, 1}\\) gets more positive, we see that the response variable \\(y\\) increases. We can clearly see the relationship between our features, so let’s see now if our model can as well!"
  },
  {
    "objectID": "posts/2022-06-13-Linear-Regression-TF.html#training-minibatch-stochiastic-gradient-descent",
    "href": "posts/2022-06-13-Linear-Regression-TF.html#training-minibatch-stochiastic-gradient-descent",
    "title": "Linear Regression with minibatch gradient descent in TensorFlow",
    "section": "Training & (minibatch stochiastic) Gradient Descent",
    "text": "Training & (minibatch stochiastic) Gradient Descent\nThis section is going to cover a few things. Specifically\n\nWhat the hell is gradient descent?\nWhy do we batch things (also what does it mean to batch things)?\nWhy are we using minibatch and what the hell is it anyway?\n\n\nGradient Descent\nGradient descent is an optimization algorithm. The main point of it is to find the minimum or maximum of a particular surface which is defined by a differentiable function. The obvious question to the layman at this point is going to be: what the hell do any of those words mean Darpan? Fair enough. Let’s get some examples going.\nA simple example of a “differentiable” function is the function \\(f(x) = x^2\\). Why is it differentiable? Because you can find the effect that changing the input will have on the out for all points (technically all points in the functions domain). That’s pretty much it. Here’s what I mean:\n\\[\n\\dfrac{d}{dx} (x^2) = 2x\n\\]\nWhy does that matter? Because gradient descent is an algorithm which looks at the fact that when you take the derivative of a given function (lets call that \\(f'(x)\\)) and plug in values, you can see how steep the original function is. Let me show you what I mean:\n\nx = np.linspace(-10, 10)\nf = x**2\n\nplt.figure(figsize = (14,7))\nplt.title(\"Derivative\")\nplt.xlim(left = min(x), right = max(x))\nplt.ylim(-40, 100)\nplt.plot(x, f, label = 'Original Function')\nplt.plot(x, [4*i - 4 for i in x], label = 'Rate of change at x = 2')\nplt.vlines(x = 2, ymin = -40, ymax = 100, linestyles='--', color='red')\nplt.legend()\nplt.show()\n\n\n\n\nWe see above that the steepness can be measured via finding the derivative of our original function at the point of x = 2:\n\\[\n\\begin{aligned}\nf'(x = 2) &= \\dfrac{d}{dx}(x^2) \\\\\n&= 2x \\\\\n&= 2(2) \\\\\nf'(x = 2) &= 4\n\\end{aligned}\n\\]\nAnd that’s exactly the slope of the orange line! Similarly, if we look at when \\(x = 5\\), we end up with \\(f'(x) = 2(5) = 10\\). That means the slope is higher on the edges of the domain (our \\(x\\) values), and lower toward the center (\\(x = 0\\)). Turns out the center is exactly where our function’s minimum value is!\nNow if we imagine we’re starting at \\(x = 5\\) and trying to get to the lowest possible value of our function, we know we have to go toward 0. Why is it that we know this? Because our brains are processing the shape and seeing “hey that’s where we’re getting the lowest.”\nThe (naive) way to get a computer to see this is through gradient descent. Here’s the general idea in mathematical form:\n\\[\na_{n+1} = a_{n} - \\gamma \\nabla F(a_n)\n\\]\nSo the entire thing above says “I’m gonna measure the slope where I’m at, and go toward the place which has the steepest slope downward.” That’s it, seriously.\n\n\\(a_n\\) is our current location (e.g. \\(x = 5\\))\n\\(\\gamma\\) is how large our steps are (e.g. should we go from 5 to 5.1 or from 5 to 5.01?)\n\\(\\nabla F(a_n)\\) is the gradient (a derivative in multiple dimensions) at the place we’re at (trying to figure out which way is an increasing slope and which way is a decreasing slope)\n\nIn our case, the slope would be the error or loss between the predicted function and the actual values.\nThere is a lot more to say about how exactly this works and why it matters so much, but this has already been more than a bite sized post so I’ll leave it at that.\n\n\nBatches ’n Stuff\nThere is a small but great article here which explains it more thoroughly than I will at the moment.\nEssentially batches are subsets of the dataset which you feed into the training loop. After one batch has been fed into the training loop, you use the results to update your model parameters. So if you have a dataset of size 100, you may take a batch size of 20, which would mean for each epoch, you’d have to update your parameters 5 times. You can refer to this as minibatch gradient descent. We’ll be using a batch size of 10. Given that our dataset has the size of 1,000 we know the number of times the parameters are updated in one epoch is:\n\\[\n\\dfrac{\\text{Dataset Size}}{\\text{Batch Size}} = \\dfrac{1000}{10} = 100 \\text{ times}\n\\]\n\ndef data_iter(batch_size, features, labels):\n    \"\"\"\n    Creating minibatches to use in training\n    \"\"\"\n    num_examples = len(features)\n    indicies = list(range(num_examples))\n    random.shuffle(indicies)\n    for i in range(0, num_examples, batch_size):\n        j = tf.constant(indicies[i : min(i + batch_size, num_examples)])\n        yield tf.gather(features, j), tf.gather(labels, j)\n\nThe rest of the code here should be relatively clear, but if it isnt here’s a brief summary:\n\nlinear_regression: Performs the actual linear regression with the tensorflow function matmul\nsquared_loss: Calculates the squared loss between the predicted and the actual values (MSE)\n\nThe final training loop simply takes the values of the number of epochs (i.e. the number of times we want to complete a training iteration) and applies the tensorflow implementation of gradient to our function, with respect to our losses and the current weights and biases. Take some time to play with this if you aren’t clear (and print things out!).\n\ndef linear_regression(X, w, b):\n    return tf.matmul(X, w) + b\n\ndef squared_loss(y_hat, y):\n    return (y_hat - tf.reshape(y, y_hat.shape))**2 / 2\n\ndef sgd(params, grads, lr, batch_size):\n    for param, grad in zip(params, grads):\n        param.assign_sub(lr*grad/batch_size)\n\nw = tf.Variable(tf.random.normal(shape=(2, 1), mean=0, stddev=0.01),\n                trainable=True)\nb = tf.Variable(tf.zeros(1), trainable=True)\n\nlr = 0.03\nnum_epochs = 3\nnet = linear_regression\nloss = squared_loss\n\n\nfor epoch in range(num_epochs):\n    for X, y in data_iter(batch_size=10, features=features, labels=labels):\n        with tf.GradientTape() as g:\n            l = loss(net(X, w, b), y)\n        dw, db = g.gradient(l, [w, b])\n        sgd([w, b], [dw, db], lr, batch_size=10)\n    train_l = loss(net(features, w, b), labels)\n    print(f\"Epoch {epoch+1}, loss {float(tf.reduce_mean(train_l)):f}\")\n\nThis is an abrupt stop, because I’ve got yet another thing I’d like to obsess about. Coming soon!"
  },
  {
    "objectID": "posts/Differential-Equations/Differential-Equations-1.html",
    "href": "posts/Differential-Equations/Differential-Equations-1.html",
    "title": "Modelling Differential Equations in Python",
    "section": "",
    "text": "Single Differential Equation (Decay)\nThe first differential differential equation we’re going to look at is simple exponential decay: \\[\n\\dfrac{dy}{dt} = -y\n\\]\nThe solution to this ODE is going to be relatively simple to find:\n\\[\n\\begin{aligned}\n\\dfrac{dy}{dt} &= -y \\\\\n- \\int \\dfrac{1}{y} dy &= \\int 1 dt \\\\\n- ln(y) + k_{1} &= t + k_{2} \\\\\nln(y) &= -t + k_{3} \\\\\ny &= Ke^{-t}\n\\end{aligned}\n\\]\nIn this case, we have one parameter that we dont know, and that is the value of \\(K\\). We can find this with an initial condition. So for example if \\(y(0) = 1\\) then we’d have that\n\\[\n\\begin{aligned}\ny(0) &= 1 = Ke^{-0} \\\\\n1 &= K\n\\end{aligned}\n\\]\nCool. Now let’s see how we can build this model and plot the solution:\n\n\nCode\nfrom scipy.integrate import solve_ivp\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn')\nplt.rcParams.update({'font.size': 12})\n\n\nFirst thing we need to work through is how to define the model. We’ll be using solve_ivp rather than odeint from the scipy.integrate library. Why? Because odeint is now outdated. I’ll provide a refrence to this later.\nIn the case of solve_ivp, we need to create our model with three things:\n\n\\(t\\): The time\n\\(y\\): The variable\nOther arguments\n\nAt this second, we’re going to ignore that last thing, because it’s not necessary for us (yet).\nHere’s how we can model decay:\n\ndef decay_model(t,y):\n    \"\"\"\n    Simple decay model\n    dy/dt = -y\n    \"\"\"\n    return -y\n\nNow that we have our model created, we can feed it into solve_ivp. To do this, we need to determine a few things. Specifically:\n\nt_span: The time over which we want to evaluate\ny0: The initial value of our function\ndense_output: Whether we want our output to be smooth\n\nNow there are many other options in solve_ivp, but for now we’ll go over these, just so we can get familiar.\nWe can set the t_span to be from \\(t = 0\\) to \\(t = 10\\), which we denote with a tuple. We can set our initial value to be 1 (like we showed above), and we want a dense output. Just to throw a curve ball in there (and not put ourselves to sleep) I’ll solve it for a variety of different initial values:\n\n\nCode\nsolution_array = list()\n\nfig, ax = plt.subplots(figsize = (14,7))\nfor i in range(0, 5):     \n    solution = solve_ivp(fun = decay_model,\n                         t_span = [0, 6],\n                         y0 = [i], \n                         dense_output=True)\n\n    ax.plot(solution.t, solution.y[0], label = fr\"$K = {i}$\")\nax.set_title(\"Exponential Decay Solution\")\nax.set_ylabel(r'$Ke^{-t}$')\nax.set_xlabel(r'$t$')\nax.set_xlim(left = 0, right = max(solution.t))\nax.set_ylim(bottom = 0)\nax.legend()\nplt.show()\n\n\n\n\n\nMultiple curves showing exponential decay\n\n\n\n\nNow I realize, this was extremely exciting and you just can’t wait for more. Don’t worry, next time we’ll implement an SIR model. And maybe mess with the populations a bit."
  },
  {
    "objectID": "posts/2022-06-03-Time-Series-Analysis-With-Python/2022-06-03-Time-Series-Analysis-With-Python.html",
    "href": "posts/2022-06-03-Time-Series-Analysis-With-Python/2022-06-03-Time-Series-Analysis-With-Python.html",
    "title": "Time Series Analysis with Python",
    "section": "",
    "text": "A couple years ago, I started learning how time series analysis works. It was so very interesting, but I didn’t really have time after a few months to dive into it properly. That’s what I’ll be doing now. Before I get started, note that I’ll be following Rob Hydman’s excellent book Forecasting: Principles and Practice. This is an attempt to refresh my own memory, and recreate the methods in the book with Python."
  },
  {
    "objectID": "posts/2022-06-03-Time-Series-Analysis-With-Python/2022-06-03-Time-Series-Analysis-With-Python.html#average",
    "href": "posts/2022-06-03-Time-Series-Analysis-With-Python/2022-06-03-Time-Series-Analysis-With-Python.html#average",
    "title": "Time Series Analysis with Python",
    "section": "Average",
    "text": "Average\nThis method is as simple as it sounds. If we want to predict the output of a given sequence at the time step \\(T + 1\\) then we take the average of all the values which came before it:\n\\[\n\\hat{y}_{T + 1} = \\dfrac{1}{T} \\sum_{i = 1}^{T} y_{i}\n\\]\n\nTip: Keep in mind that you’ll see something like this \\(\\hat{y}_{T+1 | T}\\) which simply means “the predicted value of \\(y\\) at time step \\(T+1\\) given all the previous \\(T\\) timesteps”\n\nIn R, you can use meanf. In Python (at least with the statsmodels library from what I’ve seen) we don’t have that. So we’re going to take a sample dataset of Electrical Equipment Manufacturing as a sample dataset and implement it:\n\n\nCode\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\ndf = pd.read_csv(\n    \"https://raw.githubusercontent.com/selva86/datasets/master/elecequip.csv\"\n)\ndf.date = pd.DatetimeIndex(df.date, freq=\"MS\")\ndf = df.set_index(\"date\")\n\nplt.figure(figsize=(14, 7))\nplt.title(\"Electrical Equipment Manufacturing (Euro Area)\")\nplt.plot(df.index, df.value)\nplt.xlim(left=min(df.index), right=max(df.index))\nplt.xlabel(\"Date\")\nplt.ylabel(\"Orders\")\nplt.show()\n\n\n\n\n\nNow I’ll be honest, I created my own very simple version of this for Pandas dataframes. This is not something I’d suggest using for anything other than learning:\n\ndef naive_average(y, h=1):\n    \"\"\"\n    Args: \n        y: Pandas object with DatetimeIndex\n        h: Integer forecast horizon\n    \"\"\"\n    try:\n        assert isinstance(y.index, pd.core.indexes.datetimes.DatetimeIndex)\n    except:\n        raise TypeError(\"y must be of type DatetimeIndex\")\n    try:\n        assert isinstance(h, int)\n    except:\n        raise TypeError(\"h must be of type int\")\n\n    ts = y.copy(deep=True)\n\n    if ts.index.freq is None:\n        inf_freq = pd.infer_freq(ts.index)\n        print(\n            f\"NO FREQUENCY ASSOCIATED WITH INDEX, INFERRING FREQUENCY TO BE: {inf_freq}\"\n        )\n        ts.index = pd.DatetimeIndex(ts.index, freq=inf_freq)\n\n    # Create the extended index\n    forecast_index = pd.date_range(\n        ts.index[-1], periods=h + 1, freq=ts.index.freq, inclusive=\"right\"\n    )\n    # Get the average\n    forecast_name = ts.columns[0]\n    forecast_value = np.array([ts[f\"{forecast_name}\"].mean()])\n    forecast_array = np.repeat(a=forecast_value, repeats=h)\n\n    # Create forecast dataframe\n    forecast_df = pd.DataFrame(\n        forecast_array, index=forecast_index, columns=[forecast_name]\n    )\n    return pd.concat([ts, forecast_df], axis=0)\n\nHere’s an example of our electricity prices forecasted out for 11 months with this method:\n\nforecast_df = naive_average(df, h=11)\n\nplt.figure(figsize=(14, 7))\nplt.title(\"Average Forecast\")\nplt.plot(\n    forecast_df[:\"2012-03-01\"].index,\n    forecast_df[:\"2012-03-01\"].value,\n    label=\"Original Series\",\n)\nplt.plot(\n    forecast_df[\"2012-04-01\":].index,\n    forecast_df[\"2012-04-01\":].value,\n    color=\"red\",\n    label=\"Average Forecast\",\n)\nplt.legend()\nplt.xlim(left=min(forecast_df.index), right=max(forecast_df.index))\nplt.xlabel(\"Date\")\nplt.ylabel(\"Orders\")\nplt.show()\n\nNO FREQUENCY ASSOCIATED WITH INDEX, INFERRING FREQUENCY TO BE: MS"
  },
  {
    "objectID": "posts/2022-06-03-Time-Series-Analysis-With-Python/2022-06-03-Time-Series-Analysis-With-Python.html#naive",
    "href": "posts/2022-06-03-Time-Series-Analysis-With-Python/2022-06-03-Time-Series-Analysis-With-Python.html#naive",
    "title": "Time Series Analysis with Python",
    "section": "Naive",
    "text": "Naive\nIf you thought the averaging method was simple, you’re in for a treat because the naive method is even simpler. If you want to predict \\(\\hat{y}_{T+1}\\) you simply set it equal to \\(y_{T}\\). That’s it. That’s the entire thing. For obvious reasons I’m not going to go over this:\n\\[\n\\hat{y}_{T + 1 | T} = y_{T}\n\\]"
  },
  {
    "objectID": "posts/2022-06-03-Time-Series-Analysis-With-Python/2022-06-03-Time-Series-Analysis-With-Python.html#seasonal-naive",
    "href": "posts/2022-06-03-Time-Series-Analysis-With-Python/2022-06-03-Time-Series-Analysis-With-Python.html#seasonal-naive",
    "title": "Time Series Analysis with Python",
    "section": "Seasonal Naive",
    "text": "Seasonal Naive\nA bit more interesting is the seasonal naive method, which doesn’t take the last value, but the last value of the previous season. A good example of this may be when measuring consumption of electricity, which we know is cyclic (see above). In that case, you may expect the energy consumption today to be similar to the energy consumption last year. In this case, we introduce a new variable, \\(m\\) which is the seasonal period. We can also replace the 1 we’ve been using (as a way to indicate we want to the forecast for the next time step) with \\(h\\), making it more general. So we can define this as:\n\\[\n\\hat{y}_{T+h | T} = y_{T + 1 - m(k+1)}\n\\]\nWhere \\(k\\) is the integer result of \\((h-1)/m\\)\nNow I’ve got to get going, but my post tomorrow will keep going down this road."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Learning how to learn",
    "section": "",
    "text": "Because honestly why not?\n\n\n\n\njupyter\n\n\npython\n\n\ntensorflow\n\n\nlinear-regression\n\n\n\n\n\n\n\n\n\n\n\nJun 13, 2022\n\n\nDarpan Ganatra\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIt’s been a while since I’ve brushed up on my time series forecasting techniques. Time to get on it (this is a work in progress).\n\n\n\n\njupyter\n\n\npython\n\n\ntimeseries\n\n\n\n\n\n\n\n\n\n\n\nJun 3, 2022\n\n\nDarpan Ganatra\n\n\n\n\n\n\n  \n\n\n\n\n\nWhat the heck is logistic regression and how do you implement it?\n\n\n\n\njupyter\n\n\npython\n\n\nsklearn\n\n\nlogistic_regression\n\n\n\n\n\n\n\n\n\n\n\nJun 2, 2022\n\n\nDarpan Ganatra\n\n\n\n\n\n\n  \n\n\n\n\n\nThe first in a series of tutorials to model ODEs and systems of ODEs in Python.\n\n\n\n\njupyter\n\n\npython\n\n\nmodelling\n\n\ncomp_bio\n\n\n\n\n\n\n\n\n\n\n\nMay 19, 2022\n\n\nDarpan Ganatra\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Darpan Ganatra",
    "section": "",
    "text": "My name is Darpan Ganatra. I like learning anything and everything, often times all at once. I’m currently a machine learning engineer at Amyris focused on cool bio projects."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "Darpan Ganatra",
    "section": "Education",
    "text": "Education\nNew Jersey Institute of Technology | Newark, NJ\nMSc in Data Science, Statistics Track\nRutgers University, New Brunswick | New Brunswick, NJ\nB.A. in Mathematics"
  }
]