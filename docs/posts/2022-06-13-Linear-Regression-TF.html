<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.1.251">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Darpan Ganatra">
<meta name="dcterms.date" content="2022-06-13">

<title>Math and rambling - Linear Regression with minibatch gradient descent in TensorFlow</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Math and rambling</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html">Darpan Ganatra</a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/DarpanGanatra"><i class="bi bi-github" role="img">
</i> 
 </a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/DarpanGanatra"><i class="bi bi-twitter" role="img">
</i> 
 </a>
  </li>  
</ul>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Linear Regression with minibatch gradient descent in TensorFlow</h1>
            <p class="subtitle lead">Because honestly why not?</p>
                                <div class="quarto-categories">
                <div class="quarto-category">jupyter</div>
                <div class="quarto-category">python</div>
                <div class="quarto-category">tensorflow</div>
                <div class="quarto-category">linear-regression</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Darpan Ganatra </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">June 13, 2022</p>
      </div>
    </div>
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p>Alright, so this is going to be a quick, not very in depth approach to linear regression with TensorFlow. A lot of the functions I’m using for this that have to do with TensorFlow <strong>will</strong> be explained in a later post where I describe everything as simply as possible with examples. Bear with me here. One note is that I’m taking section 3.2 of the d2l.ai book and trying to make it simpler, so you may see code overlap, but hopefully this will be much more informative and easier to read (after some revisions).</p>
<div class="cell" data-execution_count="1">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> random</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
</div>
<section id="data-generation" class="level2">
<h2 class="anchored" data-anchor-id="data-generation">Data Generation</h2>
<p>The simplest way to start as I always to is to generate the data. In this case, we’re looking to generate the data which has two features and one output. So our true equation will be of the form: <span class="math display">\[
y = \underline{X}\bar{w} + \bar{b}
\]</span> Where <span class="math inline">\(\underline{X}\)</span> is a matrix, <span class="math inline">\(\bar{w}, \bar{b}\)</span> are vectors. It’s important to know the dimensions of our matrix and vectors. Here we have <span class="math inline">\(\underline{X}\)</span> in the shape of (num_samples, num_features). So really that should be (<span class="math inline">\(n\)</span>, 2) where <span class="math inline">\(n\)</span> is the number of samples we have. Our vectors on the other hand will be of the shape:</p>
<ul>
<li><span class="math inline">\(w\)</span>: (num_samples, 1)</li>
<li><span class="math inline">\(b\)</span>: (num_samples, 1)</li>
</ul>
<p>To be as clear as possible, our equation looks like this:</p>
<p><span class="math display">\[
\begin{bmatrix}
y_1 \\
\vdots \\
y_n
\end{bmatrix}
=
\begin{bmatrix}
x_{1,1} &amp; x_{1,2} &amp; \dots &amp; x_{1, p} \\
x_{2,1} &amp; x_{2,2} &amp; \dots &amp; x_{2, p} \\
\vdots  &amp; &amp; \ddots &amp; \vdots \\
x_{n, 1} &amp; x_{n, 2} &amp; \dots &amp; x_{n, p}
\end{bmatrix}
\begin{bmatrix}
w_1 \\
\vdots \\
w_p
\end{bmatrix} +
\begin{bmatrix}
b_1 \\
\vdots \\
b_n
\end{bmatrix}
\]</span></p>
<p>By the way… this isn’t how you should usually look at linear regression. Usually you’d include <span class="math inline">\(\bar{b}\)</span> in <span class="math inline">\(\underline{X}\)</span> and <span class="math inline">\(\bar{w}\)</span>, but to be more clear we’ll seperate it here.</p>
<p>Last thing to keep in mind is that we’re adding noise (because otherwise it’s not very fun!). That noise vector <span class="math inline">\(\bar{\epsilon}\)</span> will also have a shape of (<span class="math inline">\(n\)</span>, 1), making our final equation:</p>
<p><span class="math display">\[
\begin{bmatrix}
y_1 \\
\vdots \\
y_n
\end{bmatrix}
=
\begin{bmatrix}
x_{1,1} &amp; x_{1,2} &amp; \dots &amp; x_{1, p} \\
x_{2,1} &amp; x_{2,2} &amp; \dots &amp; x_{2, p} \\
\vdots  &amp; &amp; \ddots &amp; \vdots \\
x_{n, 1} &amp; x_{n, 2} &amp; \dots &amp; x_{n, p}
\end{bmatrix}
\begin{bmatrix}
w_1 \\
\vdots \\
w_p
\end{bmatrix} +
\begin{bmatrix}
b_1 \\
\vdots \\
b_n
\end{bmatrix} +
\begin{bmatrix}
\epsilon_1 \\
\vdots \\
\epsilon_n
\end{bmatrix}
\]</span></p>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_data(w, b, num_samples):</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Create sample data of the form</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co">    y = Xw + b + epsilon </span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co">    </span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co">    Where epsilon is random noise centered around 0, std dev 0.01</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>    X <span class="op">=</span> tf.random.normal(shape<span class="op">=</span>(num_samples, w.shape[<span class="dv">0</span>]))</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    w_reshaped <span class="op">=</span> tf.reshape(w, shape<span class="op">=</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>    epsilon <span class="op">=</span> tf.random.normal(shape<span class="op">=</span>(num_samples, <span class="dv">1</span>), stddev<span class="op">=</span><span class="fl">0.01</span>)</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>    y <span class="op">=</span> tf.matmul(X, w_reshaped) <span class="op">+</span> b <span class="op">+</span> epsilon</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> X, y</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>true_w <span class="op">=</span> tf.constant([<span class="dv">2</span>, <span class="op">-</span><span class="fl">3.4</span>])</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>true_b <span class="op">=</span> <span class="fl">4.2</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>features, labels <span class="op">=</span> generate_data(true_w, true_b, <span class="dv">1000</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="data-visualization" class="level2">
<h2 class="anchored" data-anchor-id="data-visualization">Data Visualization</h2>
<p>Now we used simple parameters of <span class="math inline">\(w_1 = 2\)</span> and <span class="math inline">\(w_2 = -3.4\)</span>, with <span class="math inline">\(b = 4.2\)</span>. Here’s what our features look like:</p>
<div class="cell" data-execution_count="29">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">7</span>))</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="vs">r"$Xw + b + \epsilon$"</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>plt.scatter(features[:, <span class="dv">0</span>], labels, label<span class="op">=</span><span class="st">"Feature 1"</span>)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>plt.scatter(features[:, <span class="dv">1</span>], labels, label<span class="op">=</span><span class="st">"Feature 2"</span>)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">"Feature Matrix"</span>)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">"Label"</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="2022-06-13-Linear-Regression-TF_files/figure-html/cell-4-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="31">
<details>
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>fig <span class="op">=</span> plt.figure(figsize <span class="op">=</span> (<span class="dv">14</span>,<span class="dv">14</span>))</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> plt.axes(projection<span class="op">=</span><span class="st">'3d'</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>ax.scatter3D(features[:, <span class="dv">0</span>], </span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>             features[:, <span class="dv">1</span>], </span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>             labels, cmap <span class="op">=</span> <span class="st">'coolwarm'</span>)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span class="vs">r"$x_1$"</span>)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>ax.set_ylabel(<span class="vs">r"$x_2$"</span>)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>ax.zaxis.set_rotate_label(<span class="va">False</span>)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>ax.set_zlabel(<span class="vs">r"$y$"</span>, rotation <span class="op">=</span> <span class="dv">0</span>)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>ax.view_init(<span class="dv">20</span>, <span class="dv">140</span>)</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Training Data"</span>)</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<p><img src="2022-06-13-Linear-Regression-TF_files/figure-html/cell-5-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>As our second feature <span class="math inline">\(X_{n, 2}\)</span> gets more negative and our first feature <span class="math inline">\(X_{n, 1}\)</span> gets more positive, we see that the response variable <span class="math inline">\(y\)</span> increases. We can clearly see the relationship between our features, so let’s see now if our model can as well!</p>
</section>
<section id="training-minibatch-stochiastic-gradient-descent" class="level2">
<h2 class="anchored" data-anchor-id="training-minibatch-stochiastic-gradient-descent">Training &amp; (minibatch stochiastic) Gradient Descent</h2>
<p>This section is going to cover a few things. Specifically</p>
<ol type="1">
<li>What the hell is gradient descent?</li>
<li>Why do we batch things (also what does it mean to batch things)?</li>
<li>Why are we using minibatch and what the hell is it anyway?</li>
</ol>
<section id="gradient-descent" class="level3">
<h3 class="anchored" data-anchor-id="gradient-descent">Gradient Descent</h3>
<p>Gradient descent is an optimization algorithm. The main point of it is to find the minimum or maximum of a particular surface which is defined by a differentiable function. The obvious question to the layman at this point is going to be: what the hell do any of those words mean Darpan? Fair enough. Let’s get some examples going.</p>
<p>A simple example of a “differentiable” function is the function <span class="math inline">\(f(x) = x^2\)</span>. Why is it differentiable? Because you can find the effect that changing the input will have on the out for all points (technically all points in the functions domain). That’s pretty much it. Here’s what I mean:</p>
<p><span class="math display">\[
\dfrac{d}{dx} (x^2) = 2x
\]</span></p>
<p>Why does that matter? Because gradient descent is an algorithm which looks at the fact that when you take the derivative of a given function (lets call that <span class="math inline">\(f'(x)\)</span>) and plug in values, you can see how <strong>steep</strong> the original function is. Let me show you what I mean:</p>
<div class="cell" data-execution_count="63">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> np.linspace(<span class="op">-</span><span class="dv">10</span>, <span class="dv">10</span>)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> x<span class="op">**</span><span class="dv">2</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize <span class="op">=</span> (<span class="dv">14</span>,<span class="dv">7</span>))</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">"Derivative"</span>)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>plt.xlim(left <span class="op">=</span> <span class="bu">min</span>(x), right <span class="op">=</span> <span class="bu">max</span>(x))</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>plt.ylim(<span class="op">-</span><span class="dv">40</span>, <span class="dv">100</span>)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>plt.plot(x, f, label <span class="op">=</span> <span class="st">'Original Function'</span>)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>plt.plot(x, [<span class="dv">4</span><span class="op">*</span>i <span class="op">-</span> <span class="dv">4</span> <span class="cf">for</span> i <span class="kw">in</span> x], label <span class="op">=</span> <span class="st">'Rate of change at x = 2'</span>)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>plt.vlines(x <span class="op">=</span> <span class="dv">2</span>, ymin <span class="op">=</span> <span class="op">-</span><span class="dv">40</span>, ymax <span class="op">=</span> <span class="dv">100</span>, linestyles<span class="op">=</span><span class="st">'--'</span>, color<span class="op">=</span><span class="st">'red'</span>)</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>plt.legend()</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="2022-06-13-Linear-Regression-TF_files/figure-html/cell-6-output-1.png" class="img-fluid"></p>
</div>
</div>
<p>We see above that the <strong>steepness</strong> can be measured via finding the derivative of our original function at the point of x = 2:</p>
<p><span class="math display">\[
\begin{aligned}
f'(x = 2) &amp;= \dfrac{d}{dx}(x^2) \\
&amp;= 2x \\
&amp;= 2(2) \\
f'(x = 2) &amp;= 4
\end{aligned}
\]</span></p>
<p>And that’s exactly the slope of the orange line! Similarly, if we look at when <span class="math inline">\(x = 5\)</span>, we end up with <span class="math inline">\(f'(x) = 2(5) = 10\)</span>. That means the slope is higher on the edges of the domain (our <span class="math inline">\(x\)</span> values), and lower toward the center (<span class="math inline">\(x = 0\)</span>). Turns out the center is exactly where our function’s minimum value is!</p>
<p>Now if we imagine we’re starting at <span class="math inline">\(x = 5\)</span> and trying to get to the <strong>lowest</strong> possible value of our function, we know we have to go toward 0. Why is it that we know this? Because our brains are processing the shape and seeing “hey that’s where we’re getting the lowest.”</p>
<p>The (naive) way to get a computer to see this is through gradient descent. Here’s the general idea in mathematical form:</p>
<p><span class="math display">\[
a_{n+1} = a_{n} - \gamma \nabla F(a_n)
\]</span></p>
<p>So the entire thing above says “I’m gonna measure the slope where I’m at, and go toward the place which has the steepest slope downward.” That’s it, seriously.</p>
<ul>
<li><span class="math inline">\(a_n\)</span> is our current location (e.g.&nbsp;<span class="math inline">\(x = 5\)</span>)</li>
<li><span class="math inline">\(\gamma\)</span> is how large our steps are (e.g.&nbsp;should we go from 5 to 5.1 or from 5 to 5.01?)</li>
<li><span class="math inline">\(\nabla F(a_n)\)</span> is the <strong>gradient</strong> (a derivative in multiple dimensions) at the place we’re at (trying to figure out which way is an increasing slope and which way is a decreasing slope)</li>
</ul>
<p>In our case, the slope would be the error or loss between the predicted function and the actual values.</p>
<p>There is a <strong>lot</strong> more to say about how exactly this works and why it matters so much, but this has already been more than a bite sized post so I’ll leave it at that.</p>
</section>
<section id="batches-n-stuff" class="level3">
<h3 class="anchored" data-anchor-id="batches-n-stuff">Batches ’n Stuff</h3>
<p>There is a small but great article <a href="https://towardsdatascience.com/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9">here</a> which explains it more thoroughly than I will at the moment.</p>
<p>Essentially batches are subsets of the dataset which you feed into the training loop. After one batch has been fed into the training loop, you use the results to update your model parameters. So if you have a dataset of size 100, you may take a batch size of 20, which would mean for each epoch, you’d have to update your parameters 5 times. You can refer to this as <strong>minibatch</strong> gradient descent. We’ll be using a batch size of 10. Given that our dataset has the size of 1,000 we know the number of times the parameters are updated in one epoch is:</p>
<p><span class="math display">\[
\dfrac{\text{Dataset Size}}{\text{Batch Size}} = \dfrac{1000}{10} = 100 \text{ times}
\]</span></p>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> data_iter(batch_size, features, labels):</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Creating minibatches to use in training</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    num_examples <span class="op">=</span> <span class="bu">len</span>(features)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    indicies <span class="op">=</span> <span class="bu">list</span>(<span class="bu">range</span>(num_examples))</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    random.shuffle(indicies)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">0</span>, num_examples, batch_size):</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>        j <span class="op">=</span> tf.constant(indicies[i : <span class="bu">min</span>(i <span class="op">+</span> batch_size, num_examples)])</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">yield</span> tf.gather(features, j), tf.gather(labels, j)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>The rest of the code here should be relatively clear, but if it isnt here’s a brief summary:</p>
<ul>
<li><code>linear_regression</code>: Performs the actual linear regression with the tensorflow function <code>matmul</code></li>
<li><code>squared_loss</code>: Calculates the squared loss between the predicted and the actual values (MSE)</li>
</ul>
<p>The final training loop simply takes the values of the number of epochs (i.e.&nbsp;the number of times we want to complete a training iteration) and applies the tensorflow implementation of gradient to our function, with respect to our losses and the current weights and biases. Take some time to play with this if you aren’t clear (and print things out!).</p>
<div class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> linear_regression(X, w, b):</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> tf.matmul(X, w) <span class="op">+</span> b</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> squared_loss(y_hat, y):</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> (y_hat <span class="op">-</span> tf.reshape(y, y_hat.shape))<span class="op">**</span><span class="dv">2</span> <span class="op">/</span> <span class="dv">2</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> sgd(params, grads, lr, batch_size):</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> param, grad <span class="kw">in</span> <span class="bu">zip</span>(params, grads):</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>        param.assign_sub(lr<span class="op">*</span>grad<span class="op">/</span>batch_size)</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> tf.Variable(tf.random.normal(shape<span class="op">=</span>(<span class="dv">2</span>, <span class="dv">1</span>), mean<span class="op">=</span><span class="dv">0</span>, stddev<span class="op">=</span><span class="fl">0.01</span>),</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>                trainable<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>b <span class="op">=</span> tf.Variable(tf.zeros(<span class="dv">1</span>), trainable<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>lr <span class="op">=</span> <span class="fl">0.03</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>num_epochs <span class="op">=</span> <span class="dv">3</span></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>net <span class="op">=</span> linear_regression</span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>loss <span class="op">=</span> squared_loss</span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(num_epochs):</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> X, y <span class="kw">in</span> data_iter(batch_size<span class="op">=</span><span class="dv">10</span>, features<span class="op">=</span>features, labels<span class="op">=</span>labels):</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> tf.GradientTape() <span class="im">as</span> g:</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>            l <span class="op">=</span> loss(net(X, w, b), y)</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>        dw, db <span class="op">=</span> g.gradient(l, [w, b])</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>        sgd([w, b], [dw, db], lr, batch_size<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>    train_l <span class="op">=</span> loss(net(features, w, b), labels)</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"Epoch </span><span class="sc">{</span>epoch<span class="op">+</span><span class="dv">1</span><span class="sc">}</span><span class="ss">, loss </span><span class="sc">{</span><span class="bu">float</span>(tf.reduce_mean(train_l))<span class="sc">:f}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This is an abrupt stop, because I’ve got yet another thing I’d like to obsess about. Coming soon!</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
</div> <!-- /content -->



</body></html>